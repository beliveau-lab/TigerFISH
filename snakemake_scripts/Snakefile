configfile: "config.yml"

SAMPLES = config["samples"]
WINDOW = config["window"]
THRESH = config["threshold"]
COMPOS = config["composition"]
COPY_N = config["copy_num"]
ENRICH = config["enrich_score"]
LOCAL = config["local_val"]
GLOBAL = config["global_val"]

rule all:
    input:
        filtered_files = expand("results/lda_specificity_out/w{window}_t{threshold}_c{composition}_e{enrich_score}_cn{copy_num}_l{local_val}_g{global_val}_probes.bed", local_val = LOCAL, global_val = GLOBAL,sample = SAMPLES, window = WINDOW, threshold = THRESH, composition = COMPOS, copy_num = COPY_N, enrich_score = ENRICH)

rule generate_jf_idx:
    input:
        fasta_file = "../../../../../../reference/Assemblies/chm13/{sample}.fa",
        jf = config["jf_file"],
        chr_path = config["chr_path"] + "{sample}.fa"

    conda:
        "envs/tigerfish_pipeline.yml"

    params:
        chrom_name = "{sample}",
        file_start = config["file_start"],
        mfree = "60G",
        h_rt = "200:0:0"
    threads: 3
    benchmark:
        "results/benchmarks/generate_jf_idx/{sample}_log.log"

    output:
        "results/jf_index_files/{sample}_jf_temp.txt",
        "results/jf_index_files/{sample}_index.txt"

    shell:
        "python ../../bin/generate_jf_idxs.py -f {input.fasta_file} -j {input.jf} -chr {params.chrom_name} -schr {input.chr_path} -st {params.file_start}"

rule repeat_ID:
    input:
        jf_count = "results/jf_index_files/{sample}_jf_temp.txt",
        chrom_index = "results/jf_index_files/{sample}_index.txt",
        chr_path = config["chr_path"] + "{sample}.fa"

    conda:
        'envs/tigerfish_pipeline.yml'

    params:
        window = "{window}",
        threshold = "{threshold}",
        composition = "{composition}",
        file_start = config["file_start"],
        chrom_name = "{sample}",
        mfree="50G",
        h_rt="200:0:0"
    threads: 3
    benchmark:
        "results/benchmarks/repeat_ID/w{window}_t{threshold}_c{composition}/{sample}_log.log"

    output:
        out_bed = "results/repeat_id_out/w{window}_t{threshold}_c{composition}/{sample}_regions.bed",
        out_fasta = "results/repeat_id_out/w{window}_t{threshold}_c{composition}/{sample}_regions.fa"

    shell:
        "python ../../bin/refactor_repeatID.py -j {input.jf_count} -i {input.chrom_index} -t {params.threshold} -c {params.composition} -chr {params.chrom_name}  -st {params.file_start} -schr {input.chr_path} -o_b {output.out_bed} -o_f {output.out_fasta}"

rule design_probes:
    input:
        region_fa = "results/repeat_id_out/w{window}_t{threshold}_c{composition}/{sample}_regions.fa"

    output:
        "results/designed_probes_out/w{window}_t{threshold}_c{composition}/{sample}_blockParse_probe_df.bed"

    conda:
        'envs/tigerfish_pipeline.yml'

    params:
        mfree="40G",
        h_rt="200:0:0",
        window = "{window}",
        threshold = "{threshold}",
        composition = "{composition}",
        chrom_name = "{sample}"
    threads: 3
    benchmark:
        "results/benchmarks/design_probes/w{window}_t{threshold}_c{composition}/{sample}_log.log"

    shell:
        "python ../../bin/design_probes.py -f {input.region_fa} -chr {params.chrom_name} -win {params.window} -thresh {params.threshold} -comp {params.composition}"

rule specificity:
    input:
        jf = "results/jf_index_files/{sample}_jf_temp.txt",
        probes = "results/designed_probes_out/w{window}_t{threshold}_c{composition}/{sample}_blockParse_probe_df.bed",
        region_fa = "results/repeat_id_out/w{window}_t{threshold}_c{composition}/{sample}_regions.fa"

    conda:
        'envs/tigerfish_pipeline.yml'

    params:
        mfree="40G",
        h_rt="200:0:0",
        merlength = config["merlength"],
        enrich_score = "{enrich_score}",
        copy_num = "{copy_num}",
        window = "{window}",
        threshold = "{threshold}",
        composition = "{composition}",
        chrom_name = "{sample}"
    threads: 3
    benchmark:
        "results/benchmarks/specificity/w{window}_t{threshold}_c{composition}_e{enrich_score}_cn{copy_num}/{sample}_log.log"

    output:
        "results/initial_specificity_out/pre_filter/w{window}_t{threshold}_c{composition}_e{enrich_score}_cn{copy_num}/{sample}_probes_final_score.txt"
    shell:
        "python ../../bin/kmer_filter.py -p {input.probes} -j {input.jf} -ch {params.chrom_name} -f {input.region_fa}  -w {params.window} -t {params.threshold} -c {params.composition} -m {params.merlength} -e {params.enrich_score} -cn {params.copy_num}"

def aggregate_files(wildcards):
    files = expand('results/initial_specificity_out/pre_filter/w{window}_t{threshold}_c{composition}_e{enrich_score}_cn{copy_num}/{sample}_probes_final_score.txt', sample = SAMPLES, window = wildcards.window, threshold = wildcards.threshold, composition = wildcards.composition, enrich_score = wildcards.enrich_score, copy_num = wildcards.copy_num)
    return files

rule merge_specificity_input:
    input:
        aggregate_files
    output:
        'results/initial_specificity_out/concat/w{window}_t{threshold}_c{composition}_e{enrich_score}_cn{copy_num}_concat.bed'
    conda:
        'envs/tigerfish_pipeline.yml'
    params:
        mfree="20G",
        h_rt="200:0:0"
    threads: 3
    shell:
        'cat {input} > {output}'

rule filter_spec:
    input:
        merged_files = "results/initial_specificity_out/concat/w{window}_t{threshold}_c{composition}_e{enrich_score}_cn{copy_num}_concat.bed"
    output:
        filtered_files = "results/initial_specificity_out/post_filter/w{window}_t{threshold}_c{composition}_e{enrich_score}_cn{copy_num}_filtered.bed"
    conda:
        'envs/tigerfish_pipeline.yml'
    params:
        mfree="20G",
        h_rt="200:0:0",
        enrich_score = "{enrich_score}",
        copy_num = "{copy_num}"
    threads: 3
    shell:
        "python ../../bin/probes_filter.py -f {input.merged_files} -o {output.filtered_files} -e {params.enrich_score} -cn {params.copy_num}"

rule lda_specificity:
    input:
        pre_filter = "results/initial_specificity_out/post_filter/w{window}_t{threshold}_c{composition}_e{enrich_score}_cn{copy_num}_filtered.bed"
    output:
        post_filter = "results/lda_specificity_out/w{window}_t{threshold}_c{composition}_e{enrich_score}_cn{copy_num}_l{local_val}_g{global_val}_probes.bed"
    conda:
        'envs/tigerfish_pipeline.yml'
    params:
        mfree="80G",
        h_rt="200:0:0",
        local_val = "{local_val}",
        global_val = "{global_val}"
    shell:
        "python ../../bin/bt2_allvall.py -f {input.pre_filter} -o {output.post_filter} -t_l {params.local_val} -t_g {params.global_val}"
